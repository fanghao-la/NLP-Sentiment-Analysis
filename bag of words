__author__ = 'fang'
import pandas
import numpy
import scipy
import sklearn
import cython
from bs4 import BeautifulSoup as BS
import nltk
import gensim
import re
import os
os.getcwd()
os.chdir("C:/Users/pp/PycharmProjects/bag_of_words")

train = pandas.read_csv("C:/Users/pp/Downloads/bag_of_words/labeledTrainData.tsv", header = 0, delimiter = "\t", quoting = 3)
#type(train)
#train.shape
#train.columns.values
#print train["review"][0]

#example1 = BS(train["review"][0])
#print example1.get_text()
#letters_only = re.sub("[^a-zA-Z]", " ", example1.get_text())
#print letters_only
#lower_case = letters_only.lower()
#words = lower_case.split()

#nltk.download()
from nltk.corpus import stopwords
stop_words = set(stopwords.words("english"))
#print stop_words
#words = [w for w in words if not w in stop_words]

def review_to_word (raw_review):
    letters_only = re.sub("[^a-zA-Z]", " ", BS(raw_review).get_text())
    words = letters_only.lower().split()
    meaningful_words = [w for w in words if not w in stop_words]
    return(" ".join(meaningful_words))

review_num = train["review"].size
cleaned_train_review = []
for i in xrange(0, review_num):
    cleaned_train_review.append(review_to_word(train["review"][i]))

print "Creating the bag of words...\n"
from sklearn.feature_extraction.text import CountVectorizer
vectorizer = CountVectorizer(analyzer="word", tokenizer=None, preprocessor=None,
                             stop_words=None, max_features=2000)
train_data_features = vectorizer.fit_transform(cleaned_train_review)
train_data_features = train_data_features.toarray()
print (train_data_features.shape)
vocab = vectorizer.get_feature_names()
#print vocab

#dist = numpy.sum(train_data_features, axis=0)
#for tag, count in zip(vocab, dist):
#    print (count, tag)

print ("Training random forest...")
from sklearn.ensemble import RandomForestClassifier
forest = RandomForestClassifier(n_estimators = 50)
forest = forest.fit(train_data_features, train["sentiment"])

test = pandas.read_csv("testData.tsv", header = 0, delimiter = "\t", quoting = 3)
print (test.shape)
num_test_reviews = len(test["review"])
clean_test_reviews = []
print ("Cleaning and parsing the test set movie reviews... \n")
for i in xrange(0, num_test_reviews):
    if ((i+1)%5000 == 0):
        print ("Review %d of %d \n" %(i+1, num_test_reviews))
    clean_test_reviews.append(review_to_word(test["review"][i]))
test_data_features = vectorizer.transform(clean_test_reviews).toarray()
result = forest.predict(test_data_features)
output = pandas.DataFrame(data={"id": test["id"], "sentiment": result})
output.to_csv ("Bag_of_words_model.csv", index=False, quoting=3)

